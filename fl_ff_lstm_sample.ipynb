{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cecf53e",
   "metadata": {},
   "source": [
    "This notebook demonstrates a dataloader that can be used with all three of the machine learning types below.\n",
    "\n",
    "|<center>name|<center>server|<center>clients|<center>training|<center>training data|<center>evaluation type|<center>evaluation|<center>evaluation data|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|<center>classic machine learning|<center>yes|<center>no|<center>on server|<center>on server|<center>centralized|<center>on server|<center>on server|\n",
    "|<center>federated machine learning (Central Eval)|<center>yes|<center>yes|<center>on clients|<center>on clients|<center>centralized|<center>on server|<center>on server|\n",
    "|<center>federated machine learning (Federated Eval)|<center>yes|<center>yes|<center>on clients|<center>on clients|<center>distributed|<center>on clients|<center>on clients|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa962694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import typing\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import Model\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "#from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f6f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU using TensorFlow 2.12.0 and Flower 1.4.0\n"
     ]
    }
   ],
   "source": [
    "#overall environment settings\n",
    "\n",
    "# Make TensorFlow logs less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Training on GPU or CPU?\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "print(\n",
    "    f\"Training on {'GPU' if tf.config.get_visible_devices('GPU') else 'CPU'} using TensorFlow {tf.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebbef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "ml_type = 0 # classic ML = 0, federated ML w/ centralized evaluation = 1, federated ML w/ federated eval = 2\n",
    "\n",
    "federated_path = \"../data/24_clients/\"\n",
    "centralized_path = \"../data/01_clients/\"\n",
    "\n",
    "downsample_test_set = 0 # 0 if test set not downsampled, 1 otherwise\n",
    "\n",
    "# TODO: Add the below to a client config file\n",
    "sequence_len = 120 # 5 days * 24 hours\n",
    "past_len = sequence_len\n",
    "future_len = 24 # 1*24 hours\n",
    "sampling_rate = 1 # in time series conversion use every row (hour) in loaded datasets\n",
    "sequence_stride = 1 # in time series conversion each series is this far apart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951ebb8",
   "metadata": {},
   "source": [
    "## ***Data loading functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900620b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    \"\"\"Normalizes the data of an array by column. \n",
    "    Shifts and scales inputs into a distribution centered around 0 \n",
    "    with standard deviation 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: NDarray \n",
    "        An array of feature values.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features_normalized : NDarray\n",
    "        The original array, but normalized.\n",
    "    \"\"\"\n",
    "    data = x\n",
    "    layer = layers.Normalization()\n",
    "    layer.adapt(data)\n",
    "    features_normalized = layer(data)\n",
    "    return features_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91e58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_create(x):\n",
    "    \"\"\"Finds the class count of the input array and creates a mask that can be used\n",
    "    to randomly downsample an array of labels so that the number of \n",
    "    negative labels = the number of positive labels. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: NDarray \n",
    "        An array of feature values.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features_normalized : NDarray\n",
    "        A masked version of the input array.\n",
    "    \"\"\"\n",
    "    mask_length = x.shape[0]\n",
    "    mask = tf.reshape(x, [mask_length])\n",
    "    y, idx, class_count = tf.unique_with_counts(mask)\n",
    "    ignition_count = tf.get_static_value(class_count[1])\n",
    "    mask = mask.numpy()\n",
    "    count = 0 \n",
    "    while count < ignition_count:\n",
    "        rand_num = random.randint(0,mask_length)\n",
    "        if (mask[rand_num] == 0):\n",
    "            mask[rand_num] = 1\n",
    "            count += 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c16d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(path: str):\n",
    "    \"\"\"Loads all the csv datasets in a folder.\n",
    "    The loaded data is divided into train, validation, and test sets.\n",
    "    The data is turned into time series data\n",
    "    All the data is normalized.\n",
    "    Train and validation datasets are downsampled.\n",
    "    TODO: divide this function into smaller functions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string \n",
    "        The path to the dataset folder.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y : NDarrays\n",
    "        A masked version of the input array.\n",
    "    \"\"\"\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "\n",
    "    #load data\n",
    "    for filename in glob.glob(os.path.join(path, '*.csv')):\n",
    "        print(\"\\nnow reading \" + filename + \"\\n\")\n",
    "        #read file\n",
    "        df = pd.read_csv(filename, index_col=[0])\n",
    "        \n",
    "        df_train = df[(df['year'] < 2001)]\n",
    "        df_val = df[(df['year'] > 2001) & (df['year'] < 2012)]\n",
    "        df_test = df[(df['year'] >= 2012)]\n",
    "        \n",
    "        features = ['stl2', 't2m', 'stl1', 'stl3', 'skt', 'swvl1', 'd2m', 'swvl2']\n",
    "        train_features = df_train[features]\n",
    "        train_labels = df_train[[\"ignition\"]]\n",
    "        val_features = df_val[features]\n",
    "        val_labels = df_val[[\"ignition\"]]\n",
    "        test_features = df_test[features]\n",
    "        test_labels = df_test[[\"ignition\"]]\n",
    "        #convert to numpy\n",
    "        train_features = train_features.values\n",
    "        val_features = val_features.values\n",
    "        test_features = test_features.values\n",
    "\n",
    "        #normalize\n",
    "        train_features_normalize = normalize_data(train_features)\n",
    "        val_features_normalize = normalize_data(val_features)\n",
    "        test_features_normalize = normalize_data(test_features)\n",
    "        \n",
    "        #we want to predict at a future point\n",
    "        #so we clip the length of the features plus the hours till the future point\n",
    "        start = past_len + future_len\n",
    "        train_labels = train_labels.iloc[start:].values\n",
    "        val_labels = val_labels.iloc[start:].values\n",
    "        test_labels = test_labels.iloc[start:].values\n",
    "        \n",
    "        batch_size = 107856 #factor of 5136 (321 * 16)\n",
    "        #convert to time series data\n",
    "        train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "            train_features_normalize,\n",
    "            train_labels,\n",
    "            sampling_rate=sampling_rate,\n",
    "            sequence_length=sequence_len,\n",
    "            sequence_stride = sequence_stride,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "        val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "            val_features_normalize,\n",
    "            val_labels,\n",
    "            sampling_rate=sampling_rate,\n",
    "            sequence_length=sequence_len,\n",
    "            sequence_stride = sequence_stride,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "        test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "            test_features_normalize,\n",
    "            test_labels,\n",
    "            sampling_rate=sampling_rate,\n",
    "            sequence_length=sequence_len,\n",
    "            sequence_stride = sequence_stride,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size)\n",
    "        \n",
    "        #for bookkeeping print out the shapes of the datasets\n",
    "        for train_features, train_labels in train_dataset:\n",
    "            print(\"train_dataset features shape:\", train_features.shape)\n",
    "            print(\"targets_dataset labels shape:\", train_labels.shape)\n",
    "            break\n",
    "\n",
    "        for val_features, val_labels in val_dataset:\n",
    "            print(\"\\nval_dataset features shape:\", val_features.shape)\n",
    "            print(\"val_dataset labels shape:\", val_labels.shape)\n",
    "            break\n",
    "\n",
    "        for test_features, test_labels in test_dataset:\n",
    "            print(\"\\ntest_dataset features shape:\", test_features.shape)\n",
    "            print(\"test_dataset labels shape:\", test_labels.shape)\n",
    "            break\n",
    "       \n",
    "        # randomly downsample the data using masks\n",
    "        train_mask = mask_create(train_labels)\n",
    "        train_features_masked = tf.boolean_mask(train_features, train_mask)\n",
    "        train_labels_masked = tf.boolean_mask(train_labels, train_mask)\n",
    "        \n",
    "        val_mask = mask_create(val_labels)\n",
    "        val_features_masked = tf.boolean_mask(val_features, val_mask)\n",
    "        val_labels_masked = tf.boolean_mask(val_labels, val_mask)\n",
    "        \n",
    "        test_mask = mask_create(test_labels)\n",
    "        test_features_masked = tf.boolean_mask(test_features, test_mask)\n",
    "        test_labels_masked = tf.boolean_mask(test_labels, test_mask)\n",
    "        \n",
    "        train_x.append(train_features_masked)\n",
    "        train_y.append(train_labels_masked)\n",
    "        val_x.append(val_features_masked)\n",
    "        val_y.append(val_labels_masked)\n",
    "        if (downsample_test_set == 1):\n",
    "            test_x.append(test_features_masked)\n",
    "            test_y.append(test_labels_masked)\n",
    "        else:\n",
    "            test_x.append(test_features)\n",
    "            test_y.append(test_labels)\n",
    "        \n",
    "    print(\"\\nDone loading data.\\n\")\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a0a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_count(x):\n",
    "    \"\"\"A helper function that returns the count of class labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: NDArray \n",
    "        An array with class labels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    non_ignition_count, ignition_count : int\n",
    "        The counts of the ignition class.\n",
    "    \"\"\"\n",
    "    length = x[0].shape[0]\n",
    "    x = tf.reshape(x, [length])\n",
    "    y, idx, class_count = tf.unique_with_counts(x)\n",
    "    non_ignition_count = tf.get_static_value(class_count[0])\n",
    "    ignition_count = tf.get_static_value(class_count[1])\n",
    "    return non_ignition_count, ignition_count\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ebf755",
   "metadata": {},
   "source": [
    "## ***Model and Metrics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eadefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    #keras.metrics.F1Score(name='f1_score'),#only available with nightly build\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS):\n",
    "    inputs = keras.Input(shape=(sequence_len, trainloaders_x[0].shape[2]))\n",
    "    x = layers.LSTM(8, activation='sigmoid')(inputs)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "        \n",
    "    return model\n",
    "\n",
    "#model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23cfe0",
   "metadata": {},
   "source": [
    "## ***Federated Learning Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7420b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add epochs to client config file \n",
    "epochs = 10\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_val, y_val, tb_callback) -> None:\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val\n",
    "        self.tb_callback = tb_callback\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    # presetting config allows us to use FlowerClient with classic ml.\n",
    "    def fit(self, parameters, config = \"ServerConfig(num_rounds=5, round_timeout=None)\"):\n",
    "        print(\"in fit\")\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.x_train, self.y_train, epochs=epochs, verbose=2, callbacks=self.tb_callback)\n",
    "        return self.model.get_weights(), len(self.x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config = \"ServerConfig(num_rounds=5, round_timeout=None)\"):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc  = self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
    "        return loss, len(self.x_val), {\"tp\": tp,\n",
    "                                       \"fp\": fp,\n",
    "                                       \"tn\": tn,\n",
    "                                       \"fn\": fn,\n",
    "                                       \"accuracy\": accuracy,\n",
    "                                       \"precision\": precision,\n",
    "                                       \"recall\": recall,\n",
    "                                       \"auc\": auc,\n",
    "                                       \"prc\": prc\n",
    "                                      }\n",
    "    \n",
    "    # this method allows metrics to be passed when using a single server with no clients\n",
    "    def evaluate2(self, parameters, config = \"ServerConfig(num_rounds=5, round_timeout=None)\"):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
    "        return loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a13013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> fl.client.Client:\n",
    "\n",
    "    print(\"\\nThis is client: \", cid)\n",
    "\n",
    "    x_train_cid = trainloaders_x[int(cid)]\n",
    "    y_train_cid = trainloaders_y[int(cid)]\n",
    "    x_test_cid = testloaders_x[int(cid)]\n",
    "    y_test_cid = testloaders_y[int(cid)]\n",
    "\n",
    "    print(\"Loaded data for client: \", cid, \"\\n\")\n",
    "\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "        #keras.metrics.F1Score(name='f1_score'),#only available with nightly build\n",
    "    ]\n",
    "\n",
    "    def make_model(metrics=METRICS):\n",
    "        inputs = keras.Input(shape=(sequence_len, x_train_cid.shape[2]))\n",
    "        x = layers.LSTM(8, activation='sigmoid')(inputs)\n",
    "        x = layers.Flatten()(x)\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "            loss=keras.losses.BinaryCrossentropy(),\n",
    "            metrics=metrics)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    print(\"Making model: \", cid)\n",
    "    model = make_model()\n",
    "\n",
    "    #model.summary()\n",
    "    import datetime\n",
    "    log_dir = \"./logs/fit/\" + cid + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    tb_callback = keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "    # Create and return client\n",
    "    print(\"\\nClient CID: \" + str(cid) + \" is done.\\n\")\n",
    "    return FlowerClient(model, x_train_cid, y_train_cid, x_test_cid, y_test_cid, tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1c140",
   "metadata": {},
   "source": [
    "## ***Launch classic machine learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71106bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "now reading ../data/01_clients/dly_avg_1of1_50.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "Done loading data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: there is a random out-of-bounds error with masking, for now if it occurs run this cell again\n",
    "#load the dataset for centralized evaluation (for classic ml training and testing) \n",
    "trainloaders_x, trainloaders_y, valloaders_x, valloaders_y, testloaders_x, testloaders_y = load_datasets(centralized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c159bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save copy for federated centralized evaluation\n",
    "central_testloaders_x = testloaders_x.copy()\n",
    "central_testloaders_y = testloaders_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5917c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set nonignitions and ignitions are: (2811, 2811)\n",
      "Validation set nonignitions and ignitions are: (2534, 2534)\n",
      "Test set nonignitions and ignitions are: (44719, 1361)\n",
      "Central test set nonignitions and ignitions are: (44719, 1361)\n"
     ]
    }
   ],
   "source": [
    "count = get_value_count(trainloaders_y)\n",
    "print(\"Train set nonignitions and ignitions are:\", count)\n",
    "count = get_value_count(valloaders_y)\n",
    "print(\"Validation set nonignitions and ignitions are:\", count)\n",
    "count = get_value_count(testloaders_y)\n",
    "print(\"Test set nonignitions and ignitions are:\", count)\n",
    "count = get_value_count(central_testloaders_y)\n",
    "print(\"Central test set nonignitions and ignitions are:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc87f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "644e8292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is client:  0\n",
      "Loaded data for client:  0 \n",
      "\n",
      "Making model:  0\n",
      "\n",
      "Client CID: 0 is done.\n",
      "\n",
      "in fit\n",
      "Epoch 1/10\n",
      "176/176 - 2s - loss: 0.6299 - tp: 2136.0000 - fp: 1319.0000 - tn: 1492.0000 - fn: 675.0000 - accuracy: 0.6453 - precision: 0.6182 - recall: 0.7599 - auc: 0.7183 - prc: 0.7218 - 2s/epoch - 12ms/step\n",
      "Epoch 2/10\n",
      "176/176 - 1s - loss: 0.6127 - tp: 1887.0000 - fp: 922.0000 - tn: 1889.0000 - fn: 924.0000 - accuracy: 0.6716 - precision: 0.6718 - recall: 0.6713 - auc: 0.7262 - prc: 0.7321 - 1s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "176/176 - 1s - loss: 0.6078 - tp: 1870.0000 - fp: 881.0000 - tn: 1930.0000 - fn: 941.0000 - accuracy: 0.6759 - precision: 0.6798 - recall: 0.6652 - auc: 0.7305 - prc: 0.7390 - 1s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "176/176 - 1s - loss: 0.6029 - tp: 1849.0000 - fp: 827.0000 - tn: 1984.0000 - fn: 962.0000 - accuracy: 0.6818 - precision: 0.6910 - recall: 0.6578 - auc: 0.7354 - prc: 0.7428 - 1s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "176/176 - 1s - loss: 0.5982 - tp: 1857.0000 - fp: 805.0000 - tn: 2006.0000 - fn: 954.0000 - accuracy: 0.6871 - precision: 0.6976 - recall: 0.6606 - auc: 0.7408 - prc: 0.7483 - 1s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "176/176 - 1s - loss: 0.5941 - tp: 1822.0000 - fp: 744.0000 - tn: 2067.0000 - fn: 989.0000 - accuracy: 0.6917 - precision: 0.7101 - recall: 0.6482 - auc: 0.7453 - prc: 0.7532 - 1s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "176/176 - 1s - loss: 0.5897 - tp: 1814.0000 - fp: 723.0000 - tn: 2088.0000 - fn: 997.0000 - accuracy: 0.6941 - precision: 0.7150 - recall: 0.6453 - auc: 0.7497 - prc: 0.7570 - 1s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "176/176 - 1s - loss: 0.5866 - tp: 1842.0000 - fp: 721.0000 - tn: 2090.0000 - fn: 969.0000 - accuracy: 0.6994 - precision: 0.7187 - recall: 0.6553 - auc: 0.7535 - prc: 0.7608 - 1s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "176/176 - 1s - loss: 0.5829 - tp: 1832.0000 - fp: 687.0000 - tn: 2124.0000 - fn: 979.0000 - accuracy: 0.7037 - precision: 0.7273 - recall: 0.6517 - auc: 0.7580 - prc: 0.7637 - 1s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "176/176 - 1s - loss: 0.5799 - tp: 1803.0000 - fp: 652.0000 - tn: 2159.0000 - fn: 1008.0000 - accuracy: 0.7047 - precision: 0.7344 - recall: 0.6414 - auc: 0.7618 - prc: 0.7652 - 1s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#train single server classic ml\n",
    "#create a flower client that represents a classic ml single server\n",
    "classic_ml = client_fn(str(0))\n",
    "#set parameters for classic_ml so it can use single flower client function\n",
    "parameters = model.get_weights()\n",
    "#run fit\n",
    "history = classic_ml.fit(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0036556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters for classic_ml so it can use single flower client function\n",
    "parameters = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f25feff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 - 3s - loss: 0.8344 - tp: 1296.0000 - fp: 35672.0000 - tn: 9047.0000 - fn: 65.0000 - accuracy: 0.2245 - precision: 0.0351 - recall: 0.9522 - auc: 0.7307 - prc: 0.0662 - 3s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#evaluate single server classic ml\n",
    "loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc = classic_ml.evaluate2(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d17570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single server classic ml evaluation\n",
      "\ttp:\t1296\n",
      "\tfp:\t35672\n",
      "\ttn:\t9047\n",
      "\tfn:\t65\n",
      "\n",
      "\tloss:\t0.834442\n",
      "\tacc:\t0.224457\n",
      "\tprec:\t0.035057\n",
      "\trec:\t0.952241\n",
      "\tauc:\t0.730658\n",
      "\tprc:\t0.066188\n"
     ]
    }
   ],
   "source": [
    "print(\"Single server classic ml evaluation\\n\\\n",
    "\\ttp:\\t%d\\n\\\n",
    "\\tfp:\\t%d\\n\\\n",
    "\\ttn:\\t%d\\n\\\n",
    "\\tfn:\\t%d\\n\\n\\\n",
    "\\tloss:\\t%f\\n\\\n",
    "\\tacc:\\t%f\\n\\\n",
    "\\tprec:\\t%f\\n\\\n",
    "\\trec:\\t%f\\n\\\n",
    "\\tauc:\\t%f\\n\\\n",
    "\\tprc:\\t%f\\\n",
    "\" % (tp,fp,tn,fn,loss,accuracy,precision,recall,auc,prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634572a",
   "metadata": {},
   "source": [
    "## ***Federated machine learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92ae95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "now reading ../data/24_clients/121.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/119.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/121.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/116.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/117.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/120.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/119.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/117.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/117.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/119.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/118.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/121.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/117.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/116.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/116.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/120.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/120.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/118.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/121.625_51_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/118.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/116.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/118.625_51.75_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/120.625_50.25_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "now reading ../data/24_clients/119.625_49.5_cell.csv\n",
      "\n",
      "train_dataset features shape: (107712, 120, 8)\n",
      "targets_dataset labels shape: (107712, 1)\n",
      "\n",
      "val_dataset features shape: (51216, 120, 8)\n",
      "val_dataset labels shape: (51216, 1)\n",
      "\n",
      "test_dataset features shape: (46080, 120, 8)\n",
      "test_dataset labels shape: (46080, 1)\n",
      "\n",
      "Done loading data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TODO: there is a random out-of-bounds error with masking, for now if it occurs run this cell again\n",
    "#load the dataset for federated learning\n",
    "trainloaders_x, trainloaders_y, valloaders_x, valloaders_y, testloaders_x, testloaders_y = load_datasets(federated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a87fa766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    tps = [num_examples * m[\"tp\"] for num_examples, m in metrics]\n",
    "    fps = [num_examples * m[\"fp\"] for num_examples, m in metrics]\n",
    "    tns = [num_examples * m[\"tn\"] for num_examples, m in metrics]\n",
    "    fns = [num_examples * m[\"fn\"] for num_examples, m in metrics]\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    precisions = [num_examples * m[\"precision\"] for num_examples, m in metrics]\n",
    "    recalls = [num_examples * m[\"recall\"] for num_examples, m in metrics]\n",
    "    aucs = [num_examples * m[\"auc\"] for num_examples, m in metrics]\n",
    "    prcs = [num_examples * m[\"prc\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"tp\": sum(tps) / sum(examples),\n",
    "            \"fp\": sum(fps) / sum(examples),\n",
    "            \"tn\": sum(tns) / sum(examples),\n",
    "            \"fn\": sum(fns) / sum(examples),\n",
    "            \"accuracy\": sum(accuracies) / sum(examples),\n",
    "            \"precision\": sum(precisions) / sum(examples),\n",
    "            \"recall\": sum(recalls) / sum(examples),\n",
    "            \"auc\": sum(aucs) / sum(examples),\n",
    "            \"prc\": sum(prcs) / sum(examples)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3a97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-04 07:31:08,009 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
      "2023-06-04 07:31:09,759\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "INFO flwr 2023-06-04 07:31:10,358 | app.py:180 | Flower VCE: Ray initialized with resources: {'memory': 77318471680.0, 'CPU': 12.0, 'object_store_memory': 2147483648.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2023-06-04 07:31:10,359 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-06-04 07:31:10,359 | server.py:273 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "INFO flwr 2023-06-04 07:31:15,616 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2023-06-04 07:31:15,617 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-06-04 07:31:15,617 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-06-04 07:31:15,617 | server.py:218 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m This is client:  1\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m Loaded data for client:  1 \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m Making model:  1\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m Client CID: 1 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=26814)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m in fit\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Epoch 1/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m 43/43 - 580s - loss: 0.6822 - tp: 672.0000 - fp: 641.0000 - tn: 42.0000 - fn: 11.0000 - accuracy: 0.5227 - precision: 0.5118 - recall: 0.9839 - auc: 0.7062 - prc: 0.6883 - 580s/epoch - 13s/step\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m \u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m 43/43 - 564s - loss: 0.6440 - tp: 615.0000 - fp: 388.0000 - tn: 295.0000 - fn: 68.0000 - accuracy: 0.6662 - precision: 0.6132 - recall: 0.9004 - auc: 0.7749 - prc: 0.7643 - 564s/epoch - 13s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 07:53:02,265 | server.py:232 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2023-06-04 07:53:02,267 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-06-04 07:53:02,267 | server.py:168 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m 53/53 - 586s - loss: 0.6746 - tp: 599.0000 - fp: 448.0000 - tn: 391.0000 - fn: 240.0000 - accuracy: 0.5900 - precision: 0.5721 - recall: 0.7139 - auc: 0.6369 - prc: 0.6195 - 586s/epoch - 11s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 744s - loss: 0.7045 - tp: 177.0000 - fp: 21393.0000 - tn: 24490.0000 - fn: 20.0000 - accuracy: 0.5353 - precision: 0.0082 - recall: 0.8985 - auc: 0.8207 - prc: 0.0188 - 744s/epoch - 517ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 744s - loss: 0.7045 - tp: 177.0000 - fp: 21393.0000 - tn: 24490.0000 - fn: 20.0000 - accuracy: 0.5353 - precision: 0.0082 - recall: 0.8985 - auc: 0.8207 - prc: 0.0188 - 744s/epoch - 517ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 744s - loss: 0.7045 - tp: 177.0000 - fp: 21393.0000 - tn: 24490.0000 - fn: 20.0000 - accuracy: 0.5353 - precision: 0.0082 - recall: 0.8985 - auc: 0.8207 - prc: 0.0188 - 744s/epoch - 517ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 744s - loss: 0.7045 - tp: 177.0000 - fp: 21393.0000 - tn: 24490.0000 - fn: 20.0000 - accuracy: 0.5353 - precision: 0.0082 - recall: 0.8985 - auc: 0.8207 - prc: 0.0188 - 744s/epoch - 517ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 744s - loss: 0.7045 - tp: 177.0000 - fp: 21393.0000 - tn: 24490.0000 - fn: 20.0000 - accuracy: 0.5353 - precision: 0.0082 - recall: 0.8985 - auc: 0.8207 - prc: 0.0188 - 744s/epoch - 517ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 08:05:32,087 | server.py:182 | evaluate_round 1 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-06-04 08:05:32,088 | server.py:218 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m This is client:  1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Loaded data for client:  1 \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Making model:  1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Client CID: 1 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m in fit\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m in fit\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Epoch 1/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m 43/43 - 568s - loss: 0.6222 - tp: 577.0000 - fp: 325.0000 - tn: 358.0000 - fn: 106.0000 - accuracy: 0.6845 - precision: 0.6397 - recall: 0.8448 - auc: 0.7750 - prc: 0.7554 - 568s/epoch - 13s/step\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m Epoch 2/2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26814)\u001b[0m 43/43 - 565s - loss: 0.6027 - tp: 553.0000 - fp: 280.0000 - tn: 403.0000 - fn: 130.0000 - accuracy: 0.6999 - precision: 0.6639 - recall: 0.8097 - auc: 0.7743 - prc: 0.7573 - 565s/epoch - 13s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 08:27:33,121 | server.py:232 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-06-04 08:27:33,122 | server.py:168 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26816)\u001b[0m 53/53 - 622s - loss: 0.6655 - tp: 517.0000 - fp: 343.0000 - tn: 496.0000 - fn: 322.0000 - accuracy: 0.6037 - precision: 0.6012 - recall: 0.6162 - auc: 0.6390 - prc: 0.6274 - 622s/epoch - 12s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 816s - loss: 0.6533 - tp: 171.0000 - fp: 17501.0000 - tn: 28382.0000 - fn: 26.0000 - accuracy: 0.6196 - precision: 0.0097 - recall: 0.8680 - auc: 0.8206 - prc: 0.0183 - 816s/epoch - 567ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 816s - loss: 0.6533 - tp: 171.0000 - fp: 17501.0000 - tn: 28382.0000 - fn: 26.0000 - accuracy: 0.6196 - precision: 0.0097 - recall: 0.8680 - auc: 0.8206 - prc: 0.0183 - 816s/epoch - 567ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 816s - loss: 0.6533 - tp: 171.0000 - fp: 17501.0000 - tn: 28382.0000 - fn: 26.0000 - accuracy: 0.6196 - precision: 0.0097 - recall: 0.8680 - auc: 0.8206 - prc: 0.0183 - 816s/epoch - 567ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 816s - loss: 0.6533 - tp: 171.0000 - fp: 17501.0000 - tn: 28382.0000 - fn: 26.0000 - accuracy: 0.6196 - precision: 0.0097 - recall: 0.8680 - auc: 0.8206 - prc: 0.0183 - 816s/epoch - 567ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26816)\u001b[0m 1440/1440 - 816s - loss: 0.6533 - tp: 171.0000 - fp: 17501.0000 - tn: 28382.0000 - fn: 26.0000 - accuracy: 0.6196 - precision: 0.0097 - recall: 0.8680 - auc: 0.8206 - prc: 0.0183 - 816s/epoch - 567ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 08:41:20,253 | server.py:182 | evaluate_round 2 received 2 results and 0 failures\n",
      "INFO flwr 2023-06-04 08:41:20,253 | server.py:147 | FL finished in 4204.607913084001\n",
      "INFO flwr 2023-06-04 08:41:20,254 | app.py:218 | app_fit: losses_distributed [(1, 0.7046457231044769), (2, 0.654981255531311)]\n",
      "INFO flwr 2023-06-04 08:41:20,254 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-06-04 08:41:20,255 | app.py:220 | app_fit: metrics_distributed {'tp': [(1, 216.5), (2, 202.0)], 'fp': [(1, 21308.0), (2, 17482.5)], 'tn': [(1, 24489.0), (2, 28314.5)], 'fn': [(1, 66.5), (2, 81.0)], 'accuracy': [(1, 0.5361436605453491), (2, 0.618847668170929)], 'precision': [(1, 0.010062229819595814), (2, 0.011421198956668377)], 'recall': [(1, 0.7961220443248749), (2, 0.7497282922267914)], 'auc': [(1, 0.7337964773178101), (2, 0.7310915589332581)], 'prc': [(1, 0.01630517654120922), (2, 0.015765988267958164)]}\n",
      "INFO flwr 2023-06-04 08:41:20,255 | app.py:221 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-06-04 08:41:20,255 | app.py:222 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.7046457231044769\n",
       "\tround 2: 0.654981255531311\n",
       "History (metrics, distributed, evaluate):\n",
       "{'tp': [(1, 216.5), (2, 202.0)], 'fp': [(1, 21308.0), (2, 17482.5)], 'tn': [(1, 24489.0), (2, 28314.5)], 'fn': [(1, 66.5), (2, 81.0)], 'accuracy': [(1, 0.5361436605453491), (2, 0.618847668170929)], 'precision': [(1, 0.010062229819595814), (2, 0.011421198956668377)], 'recall': [(1, 0.7961220443248749), (2, 0.7497282922267914)], 'auc': [(1, 0.7337964773178101), (2, 0.7310915589332581)], 'prc': [(1, 0.01630517654120922), (2, 0.015765988267958164)]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26814)\u001b[0m 1440/1440 - 826s - loss: 0.6567 - tp: 233.0000 - fp: 17464.0000 - tn: 28247.0000 - fn: 136.0000 - accuracy: 0.6181 - precision: 0.0132 - recall: 0.6314 - auc: 0.6416 - prc: 0.0133 - 826s/epoch - 573ms/step\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 2\n",
    "epochs = 2\n",
    "num_rounds = 2\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 10% of available clients for training\n",
    "    fraction_evaluate=1.0,  # Sample 5% of available clients for evaluation\n",
    "    min_fit_clients=1,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=1,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=int(NUM_CLIENTS * 0.5),  # Wait until at least 75 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7538a97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-04 10:42:32,634 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
      "2023-06-04 10:42:35,986\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "INFO flwr 2023-06-04 10:42:36,527 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 12.0, 'memory': 76328850228.0, 'object_store_memory': 2147483648.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2023-06-04 10:42:36,527 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-06-04 10:42:36,527 | server.py:273 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "INFO flwr 2023-06-04 10:42:41,661 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2023-06-04 10:42:41,661 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m This is client:  1\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m Loaded data for client:  1 \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m Making model:  1\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m Client CID: 1 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=29924)\u001b[0m \n",
      "1440/1440 - 3s - loss: 0.4413 - tp: 1313.0000 - fp: 39568.0000 - tn: 94589.0000 - fn: 2770.0000 - accuracy: 0.6937 - precision: 0.0321 - recall: 0.3216 - auc: 0.5397 - prc: 0.0390 - 3s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-04 10:42:44,459 | server.py:91 | initial parameters (loss, other metrics): 0.4412809908390045, {'tp': 1313.0, 'fp': 39568.0, 'tn': 94589.0, 'fn': 2770.0, 'accuracy': 0.6937355399131775, 'precision': 0.032117608934640884, 'recall': 0.3215772807598114, 'auc': 0.5396873950958252, 'prc': 0.03895753622055054}\n",
      "INFO flwr 2023-06-04 10:42:44,459 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-06-04 10:42:44,460 | server.py:218 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m in fit\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Metal device set to: Apple M2 Max\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m This is client:  1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Loaded data for client:  1 \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Making model:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Client CID: 1 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m 43/43 - 589s - loss: 0.6984 - tp: 8.0000 - fp: 1.0000 - tn: 682.0000 - fn: 675.0000 - accuracy: 0.5051 - precision: 0.8889 - recall: 0.0117 - auc: 0.6608 - prc: 0.6702 - 589s/epoch - 14s/step\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m 43/43 - 579s - loss: 0.6342 - tp: 299.0000 - fp: 67.0000 - tn: 616.0000 - fn: 384.0000 - accuracy: 0.6698 - precision: 0.8169 - recall: 0.4378 - auc: 0.7802 - prc: 0.7742 - 579s/epoch - 13s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 11:04:27,025 | server.py:232 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2023-06-04 11:04:27,027 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m 53/53 - 584s - loss: 0.6775 - tp: 289.0000 - fp: 154.0000 - tn: 685.0000 - fn: 550.0000 - accuracy: 0.5805 - precision: 0.6524 - recall: 0.3445 - auc: 0.6275 - prc: 0.6156 - 584s/epoch - 11s/step\n",
      "1440/1440 - 3s - loss: 0.5797 - tp: 2128.0000 - fp: 51477.0000 - tn: 127399.0000 - fn: 3316.0000 - accuracy: 0.7027 - precision: 0.0397 - recall: 0.3909 - auc: 0.5653 - prc: 0.0409 - 3s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-04 11:04:29,766 | server.py:119 | fit progress: (1, 0.5796513557434082, {'tp': 2128.0, 'fp': 51477.0, 'tn': 127399.0, 'fn': 3316.0, 'accuracy': 0.7027289271354675, 'precision': 0.039697788655757904, 'recall': 0.390889048576355, 'auc': 0.5653344392776489, 'prc': 0.040927231311798096}, 1305.30451425)\n",
      "DEBUG flwr 2023-06-04 11:04:29,766 | server.py:168 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m 1440/1440 - 714s - loss: 0.5815 - tp: 191.0000 - fp: 13045.0000 - tn: 32666.0000 - fn: 178.0000 - accuracy: 0.7130 - precision: 0.0144 - recall: 0.5176 - auc: 0.6373 - prc: 0.0122 - 714s/epoch - 496ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 714s - loss: 0.5815 - tp: 191.0000 - fp: 13045.0000 - tn: 32666.0000 - fn: 178.0000 - accuracy: 0.7130 - precision: 0.0144 - recall: 0.5176 - auc: 0.6373 - prc: 0.0122 - 714s/epoch - 496ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 714s - loss: 0.5815 - tp: 191.0000 - fp: 13045.0000 - tn: 32666.0000 - fn: 178.0000 - accuracy: 0.7130 - precision: 0.0144 - recall: 0.5176 - auc: 0.6373 - prc: 0.0122 - 714s/epoch - 496ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 714s - loss: 0.5815 - tp: 191.0000 - fp: 13045.0000 - tn: 32666.0000 - fn: 178.0000 - accuracy: 0.7130 - precision: 0.0144 - recall: 0.5176 - auc: 0.6373 - prc: 0.0122 - 714s/epoch - 496ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 714s - loss: 0.5815 - tp: 191.0000 - fp: 13045.0000 - tn: 32666.0000 - fn: 178.0000 - accuracy: 0.7130 - precision: 0.0144 - recall: 0.5176 - auc: 0.6373 - prc: 0.0122 - 714s/epoch - 496ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 11:16:31,133 | server.py:182 | evaluate_round 1 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-06-04 11:16:31,134 | server.py:218 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 720s - loss: 0.5784 - tp: 144.0000 - fp: 11986.0000 - tn: 33897.0000 - fn: 53.0000 - accuracy: 0.7387 - precision: 0.0119 - recall: 0.7310 - auc: 0.8053 - prc: 0.0149 - 720s/epoch - 500ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m This is client:  1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Loaded data for client:  1 \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Making model:  1\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Client CID: 1 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m in fit\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Epoch 1/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m 43/43 - 570s - loss: 0.6050 - tp: 482.0000 - fp: 181.0000 - tn: 502.0000 - fn: 201.0000 - accuracy: 0.7204 - precision: 0.7270 - recall: 0.7057 - auc: 0.7897 - prc: 0.7837 - 570s/epoch - 13s/step\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m Epoch 2/2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m Epoch 2/2\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=29924)\u001b[0m 43/43 - 573s - loss: 0.5835 - tp: 510.0000 - fp: 205.0000 - tn: 478.0000 - fn: 173.0000 - accuracy: 0.7233 - precision: 0.7133 - recall: 0.7467 - auc: 0.7914 - prc: 0.7846 - 573s/epoch - 13s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 11:38:52,335 | server.py:232 | fit_round 2 received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=29926)\u001b[0m 53/53 - 620s - loss: 0.6639 - tp: 506.0000 - fp: 317.0000 - tn: 522.0000 - fn: 333.0000 - accuracy: 0.6126 - precision: 0.6148 - recall: 0.6031 - auc: 0.6426 - prc: 0.6287 - 620s/epoch - 12s/step\n",
      "1440/1440 - 3s - loss: 0.6068 - tp: 3094.0000 - fp: 67255.0000 - tn: 156340.0000 - fn: 3711.0000 - accuracy: 0.6920 - precision: 0.0440 - recall: 0.4547 - auc: 0.6010 - prc: 0.0463 - 3s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-04 11:38:55,069 | server.py:119 | fit progress: (2, 0.6067822575569153, {'tp': 3094.0, 'fp': 67255.0, 'tn': 156340.0, 'fn': 3711.0, 'accuracy': 0.6919878721237183, 'precision': 0.04398072510957718, 'recall': 0.4546656906604767, 'auc': 0.601047694683075, 'prc': 0.04631812870502472}, 3370.5697214580005)\n",
      "DEBUG flwr 2023-06-04 11:38:55,069 | server.py:168 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m This is client:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Loaded data for client:  0 \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Making model:  0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m Client CID: 0 is done.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29924)\u001b[0m 1440/1440 - 761s - loss: 0.6143 - tp: 230.0000 - fp: 16944.0000 - tn: 28767.0000 - fn: 139.0000 - accuracy: 0.6293 - precision: 0.0134 - recall: 0.6233 - auc: 0.6351 - prc: 0.0123 - 761s/epoch - 529ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 761s - loss: 0.6143 - tp: 230.0000 - fp: 16944.0000 - tn: 28767.0000 - fn: 139.0000 - accuracy: 0.6293 - precision: 0.0134 - recall: 0.6233 - auc: 0.6351 - prc: 0.0123 - 761s/epoch - 529ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 761s - loss: 0.6143 - tp: 230.0000 - fp: 16944.0000 - tn: 28767.0000 - fn: 139.0000 - accuracy: 0.6293 - precision: 0.0134 - recall: 0.6233 - auc: 0.6351 - prc: 0.0123 - 761s/epoch - 529ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 761s - loss: 0.6143 - tp: 230.0000 - fp: 16944.0000 - tn: 28767.0000 - fn: 139.0000 - accuracy: 0.6293 - precision: 0.0134 - recall: 0.6233 - auc: 0.6351 - prc: 0.0123 - 761s/epoch - 529ms/step\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=29926)\u001b[0m 1440/1440 - 761s - loss: 0.6143 - tp: 230.0000 - fp: 16944.0000 - tn: 28767.0000 - fn: 139.0000 - accuracy: 0.6293 - precision: 0.0134 - recall: 0.6233 - auc: 0.6351 - prc: 0.0123 - 761s/epoch - 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-06-04 11:51:39,113 | server.py:182 | evaluate_round 2 received 2 results and 0 failures\n",
      "INFO flwr 2023-06-04 11:51:39,113 | server.py:147 | FL finished in 4134.607445916\n",
      "INFO flwr 2023-06-04 11:51:39,113 | app.py:218 | app_fit: losses_distributed [(1, 0.5799275934696198), (2, 0.6118367314338684)]\n",
      "INFO flwr 2023-06-04 11:51:39,114 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-06-04 11:51:39,114 | app.py:220 | app_fit: metrics_distributed {'tp': [(1, 167.5), (2, 200.0)], 'fp': [(1, 12515.5), (2, 16813.5)], 'tn': [(1, 33281.5), (2, 28983.5)], 'fn': [(1, 115.5), (2, 83.0)], 'accuracy': [(1, 0.7258897721767426), (2, 0.6333225071430206)], 'precision': [(1, 0.013150867074728012), (2, 0.011739781126379967)], 'recall': [(1, 0.6242898404598236), (2, 0.7431252002716064)], 'auc': [(1, 0.721286952495575), (2, 0.7235794961452484)], 'prc': [(1, 0.013554776553064585), (2, 0.01395477820187807)]}\n",
      "INFO flwr 2023-06-04 11:51:39,114 | app.py:221 | app_fit: losses_centralized [(0, 0.4412809908390045), (1, 0.5796513557434082), (2, 0.6067822575569153)]\n",
      "INFO flwr 2023-06-04 11:51:39,114 | app.py:222 | app_fit: metrics_centralized {'tp': [(0, 1313.0), (1, 2128.0), (2, 3094.0)], 'fp': [(0, 39568.0), (1, 51477.0), (2, 67255.0)], 'tn': [(0, 94589.0), (1, 127399.0), (2, 156340.0)], 'fn': [(0, 2770.0), (1, 3316.0), (2, 3711.0)], 'accuracy': [(0, 0.6937355399131775), (1, 0.7027289271354675), (2, 0.6919878721237183)], 'precision': [(0, 0.032117608934640884), (1, 0.039697788655757904), (2, 0.04398072510957718)], 'recall': [(0, 0.3215772807598114), (1, 0.390889048576355), (2, 0.4546656906604767)], 'auc': [(0, 0.5396873950958252), (1, 0.5653344392776489), (2, 0.601047694683075)], 'prc': [(0, 0.03895753622055054), (1, 0.040927231311798096), (2, 0.04631812870502472)]}\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 2\n",
    "epochs = 2\n",
    "num_rounds = 2\n",
    "\n",
    "client_resources = {\"num_cpus\": 2}\n",
    "if tf.config.get_visible_devices(\"GPU\"):\n",
    "    client_resources[\"num_gpus\"] = 1\n",
    "\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: fl.common.NDArrays,\n",
    "    config: Dict[str, fl.common.Scalar],\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    \"\"\"Centralized evaluation function\"\"\"\n",
    "    model = make_model()\n",
    "    #model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    #model.build(input_shape=(BATCH_SIZE, 28, 28, 1))\n",
    "    model.set_weights(parameters)\n",
    "#    loss, accuracy = model.evaluate(central_testloaders_x, central_testloaders_y, batch_size=32, verbose=0)\n",
    "#    return loss, {\"accuracy\": accuracy}\n",
    "    loss, tp, fp, tn, fn, accuracy, precision, recall, auc, prc  = model.evaluate(central_testloaders_x[0], central_testloaders_y[0], verbose=2)\n",
    "    return loss, {\"tp\": tp,\n",
    "                  \"fp\": fp,\n",
    "                  \"tn\": tn,\n",
    "                  \"fn\": fn,\n",
    "                  \"accuracy\": accuracy,\n",
    "                  \"precision\": precision,\n",
    "                  \"recall\": recall,\n",
    "                  \"auc\": auc,\n",
    "                  \"prc\": prc\n",
    "                 }\n",
    "\n",
    "# TODO: Specify the Strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 10% of available clients for training\n",
    "    fraction_evaluate=1.0,  # Sample 5% of available clients for evaluation\n",
    "    min_fit_clients=1,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=1,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=int(NUM_CLIENTS * 0.5),  # Wait until at least 75 clients are available\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    evaluate_fn=evaluate\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "094e8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.5799275934696198\n",
       "\tround 2: 0.6118367314338684\n",
       "History (loss, centralized):\n",
       "\tround 0: 0.4412809908390045\n",
       "\tround 1: 0.5796513557434082\n",
       "\tround 2: 0.6067822575569153\n",
       "History (metrics, distributed, evaluate):\n",
       "{'tp': [(1, 167.5), (2, 200.0)], 'fp': [(1, 12515.5), (2, 16813.5)], 'tn': [(1, 33281.5), (2, 28983.5)], 'fn': [(1, 115.5), (2, 83.0)], 'accuracy': [(1, 0.7258897721767426), (2, 0.6333225071430206)], 'precision': [(1, 0.013150867074728012), (2, 0.011739781126379967)], 'recall': [(1, 0.6242898404598236), (2, 0.7431252002716064)], 'auc': [(1, 0.721286952495575), (2, 0.7235794961452484)], 'prc': [(1, 0.013554776553064585), (2, 0.01395477820187807)]}History (metrics, centralized):\n",
       "{'tp': [(0, 1313.0), (1, 2128.0), (2, 3094.0)], 'fp': [(0, 39568.0), (1, 51477.0), (2, 67255.0)], 'tn': [(0, 94589.0), (1, 127399.0), (2, 156340.0)], 'fn': [(0, 2770.0), (1, 3316.0), (2, 3711.0)], 'accuracy': [(0, 0.6937355399131775), (1, 0.7027289271354675), (2, 0.6919878721237183)], 'precision': [(0, 0.032117608934640884), (1, 0.039697788655757904), (2, 0.04398072510957718)], 'recall': [(0, 0.3215772807598114), (1, 0.390889048576355), (2, 0.4546656906604767)], 'auc': [(0, 0.5396873950958252), (1, 0.5653344392776489), (2, 0.601047694683075)], 'prc': [(0, 0.03895753622055054), (1, 0.040927231311798096), (2, 0.04631812870502472)]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018377f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
